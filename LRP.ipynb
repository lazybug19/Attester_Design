{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tf-keras-vis\n",
      "  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.0)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\santr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\santr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tf-keras-vis) (1.14.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tf-keras-vis) (10.4.0)\n",
      "Collecting deprecated (from tf-keras-vis)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting imageio (from tf-keras-vis)\n",
      "  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\santr\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.5.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\santr\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\santr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/390.3 MB 23.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 12.1/390.3 MB 29.0 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 13.9/390.3 MB 22.3 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 17.8/390.3 MB 21.6 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 21.8/390.3 MB 20.8 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 27.8/390.3 MB 22.0 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 34.1/390.3 MB 23.3 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 39.6/390.3 MB 23.5 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 41.9/390.3 MB 22.2 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 45.4/390.3 MB 21.7 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 47.7/390.3 MB 20.7 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 53.2/390.3 MB 21.0 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 61.9/390.3 MB 22.5 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 65.8/390.3 MB 22.3 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 72.1/390.3 MB 22.8 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 79.4/390.3 MB 23.5 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 83.4/390.3 MB 23.1 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 90.7/390.3 MB 23.7 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 95.7/390.3 MB 23.7 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 102.0/390.3 MB 24.0 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 108.3/390.3 MB 24.3 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 113.5/390.3 MB 24.3 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 119.5/390.3 MB 24.5 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 129.0/390.3 MB 25.3 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 133.2/390.3 MB 25.1 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 140.8/390.3 MB 25.4 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 151.0/390.3 MB 26.3 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 154.9/390.3 MB 25.9 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 161.0/390.3 MB 26.0 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 166.5/390.3 MB 26.3 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 169.9/390.3 MB 25.7 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 177.2/390.3 MB 25.9 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 182.7/390.3 MB 25.9 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 189.8/390.3 MB 26.1 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 194.5/390.3 MB 26.0 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 198.7/390.3 MB 25.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 206.0/390.3 MB 26.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 212.1/390.3 MB 26.1 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 220.5/390.3 MB 26.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 227.0/390.3 MB 26.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 234.9/390.3 MB 26.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 243.5/390.3 MB 27.1 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 245.9/390.3 MB 26.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 251.7/390.3 MB 26.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 259.0/390.3 MB 26.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 269.2/390.3 MB 27.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 281.8/390.3 MB 28.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 291.5/390.3 MB 29.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 298.1/390.3 MB 29.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 304.9/390.3 MB 29.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 312.5/390.3 MB 31.0 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 319.8/390.3 MB 30.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 328.2/390.3 MB 31.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 337.1/390.3 MB 31.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.1/390.3 MB 31.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 350.7/390.3 MB 31.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.4/390.3 MB 32.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 365.4/390.3 MB 32.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 371.2/390.3 MB 32.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.5/390.3 MB 33.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 33.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 33.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 33.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 30.7 MB/s eta 0:00:00\n",
      "Downloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 52.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 58.1 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 58.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 34.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.4/26.4 MB 28.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.4 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 26.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 41.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, imageio, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, deprecated, astunparse, tf-keras-vis, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 deprecated-1.2.14 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.0 h5py-3.12.1 imageio-2.36.0 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 tf-keras-vis-0.8.7 werkzeug-3.0.6 wheel-0.44.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\santr\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts imageio_download_bin.exe and imageio_remove_bin.exe are installed in 'c:\\Users\\santr\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\santr\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\santr\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tf-keras-vis matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "Normal                   24301\n",
      "DDoS_UDP                 14498\n",
      "DDoS_ICMP                14090\n",
      "Ransomware               10925\n",
      "DDoS_HTTP                10561\n",
      "SQL_injection            10311\n",
      "Uploading                10269\n",
      "DDoS_TCP                 10247\n",
      "Backdoor                 10195\n",
      "Vulnerability_scanner    10076\n",
      "Port_Scanning            10071\n",
      "XSS                      10052\n",
      "Password                  9989\n",
      "MITM                      1214\n",
      "Fingerprinting            1001\n",
      "Name: count, dtype: int64\n",
      "Attack_type\n",
      "Normal                   24101\n",
      "DDoS_UDP                 14498\n",
      "DDoS_ICMP                13096\n",
      "DDoS_HTTP                10495\n",
      "SQL_injection            10282\n",
      "DDoS_TCP                 10247\n",
      "Uploading                10214\n",
      "Vulnerability_scanner    10062\n",
      "Password                  9972\n",
      "Backdoor                  9865\n",
      "Ransomware                9689\n",
      "XSS                       9543\n",
      "Port_Scanning             8921\n",
      "Fingerprinting             853\n",
      "MITM                       358\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# initial preprocessing\n",
    "\n",
    "df = pd.read_csv(\"IoT_dataset.csv\", low_memory=False)\n",
    "df.head(5)\n",
    "print(df['Attack_type'].value_counts())\n",
    "from sklearn.utils import shuffle\n",
    "drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\", \n",
    "         \"http.file_data\",\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "         \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "         \"tcp.dstport\", \"udp.port\", \"mqtt.msg\"]\n",
    "df.drop(drop_columns, axis=1, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "df = shuffle(df)\n",
    "df.isna().sum()\n",
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "y = df['Attack_type']\n",
    "X = df.drop(['Attack_type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA reduces the CNN accuracy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing for CNN\n",
    "labels = df.pop('Attack_type') \n",
    "\n",
    "# Variance Threshold : Remove features with low variance\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "df = selector.fit_transform(df)\n",
    "\n",
    "# SMOTE for class balance\n",
    "smote = SMOTE(random_state=42)\n",
    "data_resampled, labels_resampled = smote.fit_resample(df, labels)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_resampled = label_encoder.fit_transform(labels_resampled)\n",
    "n_features = data_resampled.shape[1]\n",
    "square_dim = int(np.ceil(np.sqrt(n_features)))\n",
    "\n",
    "# Pad data to ensure square dimensions\n",
    "if square_dim * square_dim > n_features:\n",
    "    padding = np.zeros((data_resampled.shape[0], square_dim * square_dim - n_features))\n",
    "    data_resampled = np.hstack((data_resampled, padding))\n",
    "data_reshaped = data_resampled.reshape(data_resampled.shape[0], square_dim, square_dim, 1)\n",
    "\n",
    "num_classes = len(np.unique(labels_resampled))\n",
    "if num_classes > 2:\n",
    "    labels_resampled = to_categorical(labels_resampled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_resampled, test_size=0.2, random_state=42, stratify=labels_resampled)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MaxPooling2D in the early layers and Dropout in the later layers of a Convolutional Neural Network (CNN):\n",
    "\n",
    "### MaxPooling2D in Early Layers\n",
    "- **Dimensionality Reduction**: MaxPooling2D helps in reducing the spatial dimensions (width and height) of the input volume, which decreases the number of parameters and computations in the network, making it more efficient.\n",
    "- **Translation Invariance**: Provides a form of translation invariance, meaning the network becomes less sensitive to the exact position of features in the input image.\n",
    "- **Feature Extraction**: By focusing on the most prominent features, MaxPooling2D helps in extracting the most important features from the input data, which can be useful for the subsequent layers.\n",
    "\n",
    "### Dropout in Later Layers\n",
    "- **Prevent Overfitting**: Dropout is a regularization technique that helps in preventing overfitting by randomly setting a fraction of input units to 0 at each update during training time. This forces the network to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.\n",
    "- **Improved Generalization**: By preventing overfitting, Dropout helps in improving the generalization of the model to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.3767 - val_accuracy: 0.9913 - val_loss: 0.0230\n",
      "Epoch 2/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0365 - val_accuracy: 0.9928 - val_loss: 0.0178\n",
      "Epoch 3/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0267 - val_accuracy: 0.9951 - val_loss: 0.0120\n",
      "Epoch 4/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0205 - val_accuracy: 0.9944 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0187 - val_accuracy: 0.9951 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0162 - val_accuracy: 0.9957 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0149 - val_accuracy: 0.9957 - val_loss: 0.0126\n",
      "Epoch 8/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0469 - val_accuracy: 0.9969 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0157 - val_accuracy: 0.9950 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "\u001b[1m7291/7291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0146 - val_accuracy: 0.9962 - val_loss: 0.0101\n",
      "\u001b[1m2279/2279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0100\n",
      "Test Accuracy: 99.64%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(square_dim, square_dim, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes if num_classes > 2 else 1, activation='softmax' if num_classes > 2 else 'sigmoid')\n",
    "])\n",
    "\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, kernel_size=(3, 3), activation='sigmoid', input_shape=(square_dim, square_dim, 1)),\n",
    "#     Dropout(0.25),\n",
    "#     Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "#     Dropout(0.25),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(num_classes if num_classes > 2 else 1, activation='softmax' if num_classes > 2 else 'sigmoid')\n",
    "# ])\n",
    "\n",
    "loss_function = 'categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy'\n",
    "model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {model_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tensorflow.keras.models import Model\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
    "\n",
    "model = Model(inputs=model.input, outputs=model.output, name=\"wrapped_model\")\n",
    "gradcam = Gradcam(model,\n",
    "                  model_modifier=ReplaceToLinear(),\n",
    "                  clone=True)\n",
    "\n",
    "# Define the input data you want to interpret\n",
    "# This should be a sample that has been preprocessed similarly to your training data\n",
    "test_input = np.expand_dims(X[0], axis=0)  # Expand dims if needed for batch dimension\n",
    "\n",
    "# Apply DeepLIFT using tf-keras-vis Gradcam for visualization\n",
    "score = CategoricalScore([1])  # Target the positive class (adjust index if needed)\n",
    "cam = gradcam(score, test_input, penultimate_layer=-1)  # Penultimate layer to visualize relevance\n",
    "\n",
    "# Plot the DeepLIFT relevance heatmap\n",
    "heatmap = np.uint8(255 * cam[0])\n",
    "plt.imshow(heatmap, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
